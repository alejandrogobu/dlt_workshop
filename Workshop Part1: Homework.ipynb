{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework\n",
    "\n",
    "Write a python script that will load data from the SpaceX API into DuckDB using dlt.\n",
    "\n",
    "Use:\n",
    "- @dlt.source\n",
    "- @dlt.resource\n",
    "- @dlt.transformer\n",
    "\n",
    "SpaceX API URL: https://api.spacexdata.com\n",
    "\n",
    "Docs: https://github.com/r-spacex/SpaceX-API/blob/master/docs/README.md\n",
    "\n",
    "Endpoints for loading:\n",
    "- launches\n",
    "- rockets\n",
    "- crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dlt with duckdb extention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install dlt[duckdb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with SpaceX API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"https://api.spacexdata.com/v4/launches\")\n",
    "response.json()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper\n",
    "Run the cell and ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlt.common.pipeline import LoadInfo\n",
    "\n",
    "def assert_load_info(info: LoadInfo, expected_load_packages: int = 1) -> None:\n",
    "    \"\"\"Asserts that expected number of packages was loaded and there are no failed jobs\"\"\"\n",
    "    assert len(info.loads_ids) == expected_load_packages\n",
    "    # all packages loaded\n",
    "    assert all(package.state == \"loaded\" for package in info.load_packages) is True\n",
    "    # no failed jobs in any of the packages\n",
    "    info.raise_on_failed_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "\n",
    "Create a pipeline for SpaceX API, for the next endpoints: launches, rockets, crew.\n",
    "\n",
    "- Fill the empty lines in the functions below.\n",
    "- `get_rockets` resource should have `table_name=rockets`.\n",
    "- Create a [resource](https://dlthub.com/docs/general-usage/resource#declare-a-resource) for the `crew` endpoint from scratch.\n",
    "- [Run the pipeline](https://dlthub.com/docs/walkthroughs/run-a-pipeline) without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline spacex_with_source load step completed in 1.16 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset spacex_data_20240827124856\n",
      "The duckdb destination used duckdb:////Users/alejandrogonzalezbueno/Projects/dlt_workshop/spacex_with_source.duckdb location to store data\n",
      "Load package 1724762936.673049 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dlt\n",
    "import requests\n",
    "\n",
    "\n",
    "@dlt.resource(table_name=\"launches\")\n",
    "def get_launches():\n",
    "    # url to request launches\n",
    "    url = \"https://api.spacexdata.com/v4/launches\"\n",
    "    # make the request and check if succeeded\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    yield response.json()\n",
    "\n",
    "@dlt.resource(table_name=\"rockets\")\n",
    "def get_rockets():\n",
    "    # url to request rockets\n",
    "    url = \"https://api.spacexdata.com/v4/rockets\"\n",
    "    # make the request and check if succeeded\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    yield response.json()\n",
    "\n",
    "@dlt.resource(table_name=\"crew\")\n",
    "def get_crew():\n",
    "    # url to request crew\n",
    "    url = \"https://api.spacexdata.com/v4/crew\"\n",
    "    # make the request and check if succeeded\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    yield response.json()\n",
    "\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='spacex_with_source',\n",
    "    destination='duckdb',\n",
    "    dataset_name='spacex_data',\n",
    "    dev_mode=True,\n",
    ")\n",
    "\n",
    "load_info = pipeline.run([get_launches(), get_rockets(), get_crew()])\n",
    "print(load_info)\n",
    "assert_load_info(load_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below and\n",
    "## Answer the Question:\n",
    "- What weight (kg) has the heighest (meters) rocket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass__kg</th>\n",
       "      <th>height__meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1335000</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mass__kg  height__meters\n",
       "0   1335000           118.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# a database '<pipeline_name>.duckdb' was created in working directory so just connect to it\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "stats_table = conn.sql(\n",
    "        \"\"\"\n",
    "        SELECT mass__kg, height__meters\n",
    "        FROM rockets\n",
    "        ORDER BY height__meters DESC\n",
    "        LIMIT 1;\n",
    "        \"\"\"\n",
    ").df()\n",
    "display(stats_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "- Add pagination, read [SpaceX API doc](https://github.com/r-spacex/SpaceX-API/blob/master/docs/queries.md).\n",
    "- Combine all resources in one [source](https://dlthub.com/docs/general-usage/source) and the pipeline with `@dlt.source`.\n",
    "- Add incremental loading for resource `get_launches` using `merge` write disposition, `id` as a  primary key and `dlt.sources.incremental`.\n",
    "- Run the pipeline [only with](https://dlthub.com/docs/general-usage/source#access-and-select-resources-to-load) `get_launches` resource.\n",
    "\n",
    "Read more about [incremental loading](https://dlthub.com/docs/general-usage/incremental-loading)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try post method to query SpaceX API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "        \"https://api.spacexdata.com/v4/launches/query\",\n",
    "        json={\n",
    "            \"query\": {\n",
    "                \"date_utc\": {\n",
    "                    \"$gt\": 0,\n",
    "                  },\n",
    "            \"options\": {\n",
    "                    \"page\":1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use code above to make your launches resource incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "import requests\n",
    "\n",
    "\n",
    "@dlt.resource(table_name='launches', \n",
    "              write_disposition='merge',\n",
    "              primary_key=\"id\")\n",
    "def get_launches(date_unix=dlt.sources.incremental(\"date_unix\", initial_value=0)):\n",
    "    url = \"https://api.spacexdata.com/v4/launches/query\"\n",
    "    query_launch = {\n",
    "        \"query\": {\n",
    "            \"date_utc\": {\n",
    "                \"$gt\":date_unix.last_value\n",
    "            },\n",
    "        },\n",
    "        \"options\": {\n",
    "            \"page\": 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    current_page = 1\n",
    "    while True:\n",
    "        query_launch[\"options\"][\"page\"] = current_page\n",
    "        response = requests.post(url, json=query_launch)\n",
    "        response.raise_for_status()\n",
    "        launches = response.json()[\"docs\"]\n",
    "        if not launches:\n",
    "            break\n",
    "        \n",
    "        yield launches\n",
    "        \n",
    "        current_page += 1\n",
    "\n",
    "@dlt.resource(table_name=\"rockets\")\n",
    "def get_rockets():\n",
    "    # url to request rockets\n",
    "    url = \"https://api.spacexdata.com/v4/rockets\"\n",
    "    # make the request and check if succeeded\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    yield response.json()\n",
    "\n",
    "@dlt.resource(table_name=\"crew\")\n",
    "def get_crew():\n",
    "    # url to request crew\n",
    "    url = \"https://api.spacexdata.com/v4/crew\"\n",
    "    # make the request and check if succeeded\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    yield response.json()\n",
    "    \n",
    "@dlt.source\n",
    "def spacex_source():\n",
    "    return [get_launches, get_rockets, get_crew]\n",
    "\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='spacex_with_source_inc',\n",
    "    destination='duckdb',\n",
    "    dataset_name='spacex_data_inc',\n",
    "    #dev_mode=True,\n",
    ")\n",
    "\n",
    "data = spacex_source().with_resources(\"get_launches\")\n",
    "\n",
    "\n",
    "# Run the pipeline one more time, it should load no data\n",
    "load_info = pipeline.run(data)\n",
    "print(load_info)\n",
    "assert_load_info(load_info, expected_load_packages=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rocket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e9d0d95eda69973a809d1ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e9d0d95eda69974db09d1ed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rocket\n",
       "0  5e9d0d95eda69973a809d1ec\n",
       "1  5e9d0d95eda69974db09d1ed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar a la base de datos\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "\n",
    "# Ejecutar la consulta y obtener el DataFrame\n",
    "stats_table = conn.sql(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "            distinct rocket\n",
    "        FROM launches\n",
    "        WHERE \n",
    "            date_utc BETWEEN '2022-11-01 00:00:00+00:00' AND '2022-11-02 00:00:00+00:00'\"\"\"\n",
    ").df()\n",
    "\n",
    "display(stats_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Get payloads of launches\n",
    "\n",
    "Use `@dlt.transformer` to get additional info for your data.\n",
    "\n",
    "Read more about dlt [transformers](https://dlthub.com/docs/general-usage/resource#process-resources-with-dlttransformer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline spacex_with_source_tr__ load step completed in ---\n",
      "0 load package(s) were loaded to destination duckdb and into dataset None\n",
      "The duckdb destination used duckdb:////Users/alejandrogonzalezbueno/Projects/dlt_workshop/spacex_with_source_tr__.duckdb location to store data\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import requests\n",
    "\n",
    "@dlt.resource(table_name='launches', \n",
    "              write_disposition='merge',\n",
    "              primary_key=\"id\")\n",
    "def get_launches(date_unix=dlt.sources.incremental(\"date_unix\", initial_value=0)):\n",
    "    url = \"https://api.spacexdata.com/v4/launches/query\"\n",
    "    query_launch = {\n",
    "        \"query\": {\n",
    "            \"date_utc\": {\n",
    "                \"$gt\":date_unix.last_value\n",
    "            },\n",
    "        },\n",
    "        \"options\": {\n",
    "            \"page\": 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    current_page = 1\n",
    "    while True:\n",
    "        query_launch[\"options\"][\"page\"] = current_page\n",
    "        response = requests.post(url, json=query_launch)\n",
    "        response.raise_for_status()\n",
    "        launches = response.json()[\"docs\"]\n",
    "\n",
    "        if not launches:\n",
    "            break\n",
    "        \n",
    "        yield launches\n",
    "        \n",
    "        current_page += 1\n",
    "\n",
    "\n",
    "@dlt.transformer(table_name='details')\n",
    "def get_payloads(items):\n",
    "    if not items:\n",
    "        return\n",
    "\n",
    "    for i in items:\n",
    "        url = \"https://api.spacexdata.com/v4/payloads/query\"\n",
    "        query_payload = {\n",
    "            \"query\": {\n",
    "                \"launch\": i['id']  # Use the launch ID in the query\n",
    "            }\n",
    "        }\n",
    "        response = requests.post(url, json=query_payload)\n",
    "        response.raise_for_status()\n",
    "        yield response.json()[\"docs\"]\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='spacex_with_source_tr__',\n",
    "    destination='duckdb',  # or any other destination\n",
    "    dataset_name='spacex_data',\n",
    "    #dev_mode=True,\n",
    ")\n",
    "\n",
    "data = get_launches | get_payloads\n",
    "\n",
    "\n",
    "# Run the pipeline using the transformer 'enrich_launches_with_payloads'\n",
    "load_info = pipeline.run(data())\n",
    "print(load_info)\n",
    "#assert_load_info(load_info, expected_load_packages=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'date_utc': {'$gt': 1670198400}}, 'options': {'page': 22}}\n",
      "[]\n",
      "Pipeline test_11 load step completed in 1.07 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset spacex_data\n",
      "The duckdb destination used duckdb:////Users/alejandrogonzalezbueno/Projects/dlt_workshop/test_11.duckdb location to store data\n",
      "Load package 1725288877.4435048 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import requests\n",
    "\n",
    "@dlt.resource(table_name='launches', \n",
    "              write_disposition='merge',\n",
    "              primary_key=\"id\")\n",
    "def get_launches(date_unix=dlt.sources.incremental(\"date_unix\", initial_value=0)):\n",
    "    url = \"https://api.spacexdata.com/v4/launches/query\"\n",
    "    query_launch = {\n",
    "        \"query\": {\n",
    "            \"date_utc\": {\n",
    "                \"$gt\":0\n",
    "            },\n",
    "        },\n",
    "        \"options\": {\n",
    "            \"page\": 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    current_page = 1\n",
    "    while True:\n",
    "        query_launch[\"options\"][\"page\"] = current_page\n",
    "        print(query_launch)\n",
    "        response = requests.post(url, json=query_launch)\n",
    "        response.raise_for_status()\n",
    "        launches = response.json()[\"docs\"]\n",
    "        print(launches)\n",
    "\n",
    "        if not launches:\n",
    "            break\n",
    "        \n",
    "        yield launches\n",
    "        \n",
    "        current_page += 1\n",
    "\n",
    "\n",
    "data = get_launches\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='test_11',\n",
    "    destination='duckdb',  # or any other destination\n",
    "    dataset_name='spacex_data',\n",
    "    #dev_mode=True,\n",
    ")\n",
    "\n",
    "# Run the pipeline using the transformer 'enrich_launches_with_payloads'\n",
    "load_info = pipeline.run(data())\n",
    "print(load_info)\n",
    "#assert_load_info(load_info, expected_load_packages=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_dlt_loads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_dlt_pipeline_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_dlt_version</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name\n",
       "0           _dlt_loads\n",
       "1  _dlt_pipeline_state\n",
       "2         _dlt_version"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar a la base de datos\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "\n",
    "# Ejecutar la consulta y obtener el DataFrame\n",
    "stats_table = conn.sql('show tables').df()\n",
    "\n",
    "display(stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "        \"https://api.spacexdata.com/v4/launches/query\",\n",
    "        json={\n",
    "            \"query\": {\n",
    "                \"date_utc\": {\n",
    "                    \"$gt\": 999999999999,\n",
    "                  },\n",
    "            \"options\": {\n",
    "                    \"page\":1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "response.json()['docs']\n",
    "launches = response.json()['totalPages']\n",
    "print(launches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What regime has Satellite \"FalconSAT-2\" with launch id: 5eb87cd9ffd86e000604b32a?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
